"""
ç›®å‰å°±åˆ°æ­¤ä¸ºæ­¢äº†å§ï¼Œæ—¶é—´ä¸å¤šäº†ï¼ˆ8æœˆ5å·æ™šï¼‰ï¼Œè¿˜æœ‰å…¶ä»–äº‹è¦å¿™
ä½¿ç”¨äº†requestså’Œetreeï¼Œurllibå’ŒBeautifulSoupè¿˜æ²¡ç”¨
ä¸ä¼šä½¿ç”¨**æ­£åˆ™è¡¨è¾¾å¼**å°†çˆ¬å–çš„å†…å®¹ç­›é€‰ï¼Œå­¦ä¼šåå¯ä»¥å°è¯•æå–ç”µå½±ç§ç±»ã€ä¸Šæ˜ æ—¶é—´
è¿˜æœ‰å¯ä»¥å°è¯•é€šè¿‡æ‰“å¼€ç”µå½±çš„é“¾æ¥è·å–æ›´å®Œæ•´çš„ä¿¡æ¯ï¼Œå¦‚æ¼”å‘˜åˆ—è¡¨
"""

import requests
from lxml.html import etree  # æ–°ç‰ˆlxmlä¸­å¦‚æœè¦ä½¿ç”¨etreeï¼Œéœ€è¦ä½¿ç”¨lxml.html
import pandas as pd  # csvæ–‡ä»¶ç”¨

number_lists = []
title_lists = []
link_lists = []
score_lists = []
info_lists = []
quote_lists = []


def getpage(page):
    url = 'https://book.douban.com/top250?start={}'.format((page - 1) * 25)  # formatå‡½æ•°å®ç°ç¿»é¡µ
    # headeråœ¨F12ä¸­çš„Networkä¸­ï¼Œå†åˆ·æ–°ä¸€ä¸‹å¯ä»¥æ‰¾åˆ°
    header = {
        'User-Agent': "Mozilla/5.0(Windows NT 10.0;Win64;x64) AppleWebKit/537.36(KHTML, likeGecko) Chrome/75.0.3770.142Safari/537.36"}
    req = requests.get(url, headers=header)  # è·å–URL
    # print(req.text)  # çœ‹ç½‘é¡µæºç 
    return req.text


def parse(text):  # è§£ææ•°æ®
    html = etree.HTML(text)  # åˆå§‹åŒ–&æ ‡å‡†åŒ–
    # xpath()è¿”å›**åˆ—è¡¨**
    # ä¸€å¼€å§‹ä¸çŸ¥é“æ˜¯åˆ—è¡¨ï¼Œåˆappendåˆ°å¦ä¸€ä¸ªåˆ—è¡¨é‡Œï¼Œå¯¼è‡´æœ‰ä¸¤å±‚ä¸­æ‹¬å·ï¼Œforå¾ªç¯åªèƒ½ç®—ä¸€ä¸ªï¼Œä½¿ç”¨replaceä¼šå¯¼è‡´æ— æ³•è¯†åˆ«åˆ—è¡¨ï¼Œåªèƒ½ç®—str
    # å› ä¸ºæºç å«æœ‰å¤šä¸ªdivå’Œspanï¼Œéœ€è¦æ ‡æ³¨åºå·ï¼›éƒ¨åˆ†éœ€è¦text()ï¼Œå¦åˆ™ä¼šæŠ¥é”™
    contents_title = html.xpath('//td[2]/div[1]/a/@title')
    contents_url = html.xpath('//td[2]/div[1]/a/@href')
    contents_score = html.xpath('//td[2]/div[2]/span[2]/text()')
    contents_info = html.xpath('//td[2]//p[1]/text()')  # æ—¥æœŸä¹Ÿæ˜¯æœ‰\xa0/\xa0å‡ºç°ï¼Œç›®å‰æ— æ³•è§£å†³
    contents_quote = html.xpath('//td[2]//p[2]/span/text()')
    print(contents_quote)
    # contents_txt = zip(contents_title, contents_url, contents_score, contents_info, contents_quote) # å¥½å‡ æœ¬ä¹¦éƒ½æ²¡æœ‰quote
    contents_txt = zip(contents_title, contents_url, contents_score, contents_info)
    # zip()å‡½æ•°ï¼Œcontents=[(contents_title,contents_urlï¼Œ contents_score),()...]ï¼Œæ˜¯å…ƒç»„
    return contents_txt, contents_title, contents_url, contents_score, contents_info, contents_quote


def write(data):
    raw_contents = getpage(data)  # æ­¤å¤„æˆ‘é‡åˆ°äº†ä¸€ä¸ªé—®é¢˜ï¼šåºå·ç‰¹åˆ«å¤šï¼Œç»“æœå‘ç°å†…å®¹ä½¿ç”¨çš„æ˜¯æ²¡æœ‰parseè¿‡çš„æ•°æ®ğŸ˜“
    contents, titles, urls, scores, info, quote = parse(raw_contents)
    title_lists.extend(titles)  # å°†å¤šä¸ªç½‘é¡µçš„å†…å®¹æ‹¼æ¥åˆ°ä¸€ä¸ªåˆ—è¡¨
    link_lists.extend(urls)
    score_lists.extend(scores)
    info_lists.extend(info)
    quote_lists.extend(quote)
    print(len(title_lists))
    print(len(link_lists))
    print(len(score_lists))
    print(len(info_lists))
    print(len(quote_lists))
    a = 0
    # æ–¹æ³•ä¸€(txt)ï¼š
    with open('douban_book_top250(txt).txt', 'a', encoding='utf-8') as f:
        for content_tuple in contents:
            f.write("No " + str((i - 1) * 25 + a + 1) + ":\t")  # åºå·
            a += 1
            # ä¸ä¼šæ­£åˆ™è¡¨è¾¾å¼ï¼Œä¸ä¼šåˆ†å‰²ï¼Œå¯¹\xa0/\xa0å‡ºç°ç­‰é—®é¢˜ä½¿ç”¨æ¯”è¾ƒåŸå§‹çš„replaceå‡½æ•°
            content1 = str(content_tuple).replace('(', '')
            content2 = content1.replace(')', '')
            content3 = content2.replace('\'', '')
            content4 = content3.replace(',', ' ')
            content5 = content4.replace('\\xa0', '')
            content6 = content5.replace('/', '', 1)
            content7 = content6.replace('\\n                            ', '')
            content8 = content7.replace("\\n", '')
            f.write(content8.strip() + '\n')


for i in range(1, 10):
    write(i)
    print(f"æ­£åœ¨çˆ¬å–ç¬¬{i}é¡µ")

# æ–¹æ³•äºŒ(csv)ï¼š
b = 0
for x in range(len(title_lists)):
    number_lists.append(b + 1)
    b += 1
# contents_info = {'number': number_lists, 'name': title_lists, 'link': link_lists, 'score': score_lists}
contents_info = {'number': number_lists, 'name': title_lists, 'link': link_lists,
                 'score': score_lists, 'info': info_lists}
# contents_info = {'number': number_lists, 'name': title_lists, 'link': link_lists,
#                  'score': score_lists, 'info': info_lists, 'quote': quote_lists}
# å¥½å‡ æœ¬ä¹¦éƒ½æ²¡æœ‰quoteï¼Œä¹Ÿä¸æ¸…æ¥šæœ‰ä»€ä¹ˆåŠæ³•å¿«é€ŸåŠ ç©ºå€¼ï¼Œå…ˆè¿™æ ·å§
print(contents_info)
frame = pd.DataFrame(contents_info)  # csvæ–‡ä»¶
frame.to_csv(r'D:\programme_study\Python_work\crawler\douban_book_top250(csv).csv')  # ä¹±ç çš„è¯ï¼Œè®°äº‹æœ¬æ‰“å¼€ï¼Œè½¬ç ANSI
print(frame)
